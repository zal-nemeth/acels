{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QJKWqXxoBNpE"
   },
   "source": [
    "# A.C.E.L.S. Position Sensing NN Program"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2WzEx3eiBIk7"
   },
   "source": [
    "### Define Path to Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTCAnitgRDQI"
   },
   "outputs": [],
   "source": [
    "# Define paths to model files\n",
    "import os\n",
    "MODELS_DIR = 'models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1KZI3GmtnABs"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Frgw_Zz_m4Tn"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ci-NKWsQnHVH"
   },
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IAegE6LnKeg"
   },
   "outputs": [],
   "source": [
    "# Assign dataset to data variable\n",
    "data = pd.read_csv('position_data_float_xyz_extended.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gykriL9tntGs"
   },
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "go3Kh0kzYUhm",
    "outputId": "c15d08bf-5b61-443c-ed92-f2e20e97fe81"
   },
   "outputs": [],
   "source": [
    "# Check dataset\n",
    "data.head()\n",
    "num_rows = data.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fAFB7XpYTMB",
    "outputId": "5f572821-f5be-4ff5-b9a5-602774f2798d"
   },
   "outputs": [],
   "source": [
    "# Check datatype\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.dtypes\n",
    "\n",
    "# Convert dataframe to float 32\n",
    "data32 = data.astype(np.float32)\n",
    "data32.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "RmymLRgHZnBS",
    "outputId": "6d97a72a-b9b3-4315-d9d4-76491f124ee5"
   },
   "outputs": [],
   "source": [
    "# Obtain data statistics\n",
    "train_stats = data32.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "\n",
    "print(train_stats)\n",
    "\n",
    "# Separate Data into Feature and Target Variables\n",
    "# The `_og` suffix refers to the original data without normalization\n",
    "# It is assign to a variable to be later used for testing purposes\n",
    "feature_data_og = data32[['s1','s2','s3','s4','s5','s6','s7','s8']]\n",
    "target_data_og = data32[['x', 'y', 'z']]\n",
    "\n",
    "# Check data shape and type\n",
    "print(feature_data_og.shape[0])\n",
    "print(type(feature_data_og.shape[0]))\n",
    "\n",
    "# Split the data into  training and test sections\n",
    "TRAIN_SPLIT = int(0.6 * feature_data_og.shape[0])\n",
    "TEST_SPLIT = int(0.2 * feature_data_og.shape[0] + TRAIN_SPLIT)\n",
    "\n",
    "feature_train_og, feature_test_og, feature_validate_og = np.split(feature_data_og, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "target_train_og, target_test_og, target_validate_og = np.split(target_data_og, [TRAIN_SPLIT, TEST_SPLIT])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "vnW13cPqnwxo",
    "outputId": "565daa9f-f3db-45f1-9f24-91ccf22d01c3"
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normed_data = norm(data32)\n",
    "\n",
    "normed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fcin_dVkoGPg"
   },
   "outputs": [],
   "source": [
    "# Separate Data into Feature and Target Variables\n",
    "feature_data = normed_data[['s1','s2','s3','s4','s5','s6','s7','s8']]\n",
    "target_data = normed_data[['x', 'y', 'z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OEsRLwiirhGM"
   },
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature_data\n",
    "target = target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "sLw77jG45zUo",
    "outputId": "16ce53a5-c088-4092-9d7d-903f4a9b04c4"
   },
   "outputs": [],
   "source": [
    "# Assign 60% of data for training\n",
    "# Assign 20% of data for testing\n",
    "# Assign 20% pf data to validation\n",
    "TRAIN_SPLIT = int(0.6 * feature.shape[0])\n",
    "TEST_SPLIT = int(0.2 * feature.shape[0] + TRAIN_SPLIT)\n",
    "\n",
    "feature_train, feature_test, feature_validate = np.split(feature, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "target_train, target_test, target_validate = np.split(target, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "# Check split data\n",
    "feature_train.head()\n",
    "target_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7VKYXc9hu_z1"
   },
   "source": [
    "### Building and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bbgFOflzksO",
    "outputId": "fc16f06a-364d-4444-8603-13b31826fe2b"
   },
   "outputs": [],
   "source": [
    "# Create model with 8 input, 3 output and 5 hidden layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(60, activation='tanh', input_shape=(8,)))\n",
    "model.add(Dense(80, activation='tanh'))\n",
    "model.add(Dense(80, activation='tanh'))\n",
    "model.add(Dense(60, activation='tanh'))\n",
    "model.add(Dense(30, activation='tanh'))\n",
    "model.add(Dense(3))\n",
    "model.compile(optimizer='nadam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e1Ghtdm251a",
    "outputId": "9beb9ed7-5ded-4ffb-979e-5b61d50afba6"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "history_1 = model.fit(feature_train, target_train, epochs=50, batch_size=64, validation_data=(feature_validate, target_validate))\n",
    "# Check Mean Absolute Error\n",
    "test_loss, test_mae = model.evaluate(feature_test, target_test, verbose=0) \n",
    "print('Testing set Mean Abs Error: {:5.3f} mm'.format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phkKKClZRvxV",
    "outputId": "2dc90d61-1686-4e7f-f431-57f92f18e19b"
   },
   "outputs": [],
   "source": [
    "# Save model to disk\n",
    "model.save(MODEL_TF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GvLmoq1YB1nS"
   },
   "source": [
    "## Plot Metrics and Analyse Model Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XYdZ5hQkDE87"
   },
   "source": [
    "1. Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "bwZTRj7o88l-",
    "outputId": "fbdd3f90-d14f-484d-c92a-d2fd0ff3594c"
   },
   "outputs": [],
   "source": [
    "# Plot Mean Squared Error\n",
    "train_loss = history_1.history['loss']\n",
    "val_loss = history_1.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "wuHnp-j0Cd7_",
    "outputId": "1a44b29d-d2ee-46a4-8bb4-d05076afd9e4"
   },
   "outputs": [],
   "source": [
    "# Skip first 50 values and replot graph\n",
    "SKIP = 50\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oDPGPehzDJR5"
   },
   "source": [
    "2. Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "tme9v_7JC6Ju",
    "outputId": "64a98493-c370-4d99-f19f-22bdef0ffd36"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "# Draw a graph of mean absolute error, which is another way of\n",
    "# measuring the amount of error in the prediction.\n",
    "train_mae = history_1.history['mae']\n",
    "val_mae = history_1.history['val_mae']\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and Validation Mean Absolute Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the loss on our test dataset\n",
    "test_loss, test_mae = model.evaluate(feature_test, target_test)\n",
    "\n",
    "# Make predictions based on our test dataset\n",
    "target_test_pred = model.predict(feature_test)\n",
    "\n",
    "# print(feature_test)\n",
    "# print(target_test)\n",
    "#print(target_test_pred)\n",
    "\n",
    "# print(feature_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "df_sensors = feature_test\n",
    "df_coordinates = target_test\n",
    "coordinates2 = target_test_pred\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# scatter3D requires x, y, and z to be one-dimensional arrays\n",
    "x = df_coordinates.iloc[:, 0]\n",
    "y = df_coordinates.iloc[:, 1]\n",
    "z = df_coordinates.iloc[:, 2]\n",
    "\n",
    "x2 = coordinates2[:, 0]\n",
    "y2 = coordinates2[:, 1]\n",
    "z2 = coordinates2[:, 2]\n",
    "\n",
    "ax.scatter3D(x2, y2, z2, c='red', s=8, alpha=0.5, label='Model predictions')  \n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "ax.scatter3D(x, y, z, c='blue', s=15, label='Actual Normalized Values')\n",
    "\n",
    "plt.legend()  # Show legend to differentiate between the two sets\n",
    "plt.show()\n",
    "\n",
    "diff_list = []\n",
    "diff_tracker = 0\n",
    "for i, (actual, predicted) in enumerate(zip(x, x2)):\n",
    "    diff = actual/predicted*100\n",
    "    diff_tracker += diff\n",
    "    \n",
    "avrg_diff = diff_tracker/i\n",
    "\n",
    "print(f\"Average difference {avrg_diff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCfxS0FhDXcd",
    "outputId": "006bf599-ed48-45d2-d8ed-4d6ebf015f7d"
   },
   "outputs": [],
   "source": [
    "# Check Mean Absolute Error\n",
    "test_loss, test_mae = model.evaluate(feature_test, target_test, verbose=0)\n",
    "\n",
    "print('Testing set Mean Abs Error: {:5.3f} mm'.format(test_mae))\n",
    "\n",
    "# Convert to numpy arrays if they are pandas DataFrames\n",
    "original_data = target_test.to_numpy()\n",
    "predicted_data = target_test_pred\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = np.mean((original_data - predicted_data) ** 2)\n",
    "\n",
    "# Convert to Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Estimate the range of the data\n",
    "data_range = np.max(original_data) - np.min(original_data)\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "accuracy = (1 - rmse / data_range) * 100\n",
    "accuracy_percentage = np.clip(accuracy, 0, 100)  # Ensure the percentage is between 0 and 100\n",
    "\n",
    "print(\"\\n#-----------------------------------------------------\")\n",
    "print(f\"# Model Accuracy: {accuracy_percentage:.2f}%\")\n",
    "print(\"#-----------------------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tVzPrHC94NAu"
   },
   "source": [
    "## Denormalize output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Ow03NDQC6Z9p",
    "outputId": "cbfa6728-6d5a-4c99-c7d0-6a6fff47f60a"
   },
   "outputs": [],
   "source": [
    "# Check model output values\n",
    "pred_df = pd.DataFrame(target_test_pred, columns = ['x','y','z'])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "Ek39eQt24LzX",
    "outputId": "77dd3414-0bae-4f39-9c15-610ff151388e"
   },
   "outputs": [],
   "source": [
    "# Denormalize Values\n",
    "def denorm(x):\n",
    "  return (x * train_stats['std']) + train_stats['mean']\n",
    "\n",
    "denormed_data = denorm(pred_df)\n",
    "denormed_feature = denorm(feature)\n",
    "denormed_target = denorm(target)\n",
    "\n",
    "print(denormed_data.shape)\n",
    "print(denormed_feature.shape)\n",
    "\n",
    "print(f\"Denormalized Mean Absolute Error {denorm(test_mae)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denormalized Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Assuming df_sensors is the 808x8 DataFrame, df_coordinates is the 808x3 DataFrame,\n",
    "# and coordinates2 is the second 808x3 NumPy array\n",
    "df_sensors = denormed_feature[['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8']]\n",
    "df_coordinates = denormed_target[['x', 'y', 'z']]\n",
    "coordinates2 = denormed_data[['x', 'y', 'z']]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# scatter3D requires x, y, and z to be one-dimensional arrays\n",
    "x2 = coordinates2.iloc[:, 0]\n",
    "y2 = coordinates2.iloc[:, 1]\n",
    "z2 = coordinates2.iloc[:, 2]\n",
    "\n",
    "ax.scatter3D(x2, y2, z2, c='red', s=8, label='Model predictions')  # Plot second set with different color\n",
    "\n",
    "x = df_coordinates.iloc[:, 0]\n",
    "y = df_coordinates.iloc[:, 1]\n",
    "z = df_coordinates.iloc[:, 2]\n",
    "\n",
    "ax.scatter3D(x, y, z, c='blue', s=15, label='Actual values')\n",
    "ax.set_xlabel('X (mm)')\n",
    "ax.set_ylabel('Y (mm)')\n",
    "ax.set_zlabel('')\n",
    "ax.text2D(1.02, 0.55, 'Z (mm)', transform=ax.transAxes, verticalalignment='center')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"scatter_plot_4.svg\", format='svg', bbox_inches='tight', pad_inches=0)\n",
    " \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_test_pred.shape)\n",
    "\n",
    "print(target_test.shape)\n",
    "\n",
    "print(denormed_target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays if they are pandas DataFrames\n",
    "original_data = target_test_og.to_numpy()\n",
    "predicted_data = coordinates2\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = np.mean((original_data - predicted_data) ** 2)\n",
    "\n",
    "# Convert to Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Estimate the range of the data\n",
    "data_range = np.max(original_data) - np.min(original_data)\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "accuracy = (1 - rmse / data_range) * 100\n",
    "accuracy_percentage = np.clip(accuracy, 0, 100)  # Ensure the percentage is between 0 and 100\n",
    "\n",
    "# accuracy_percentage\n",
    "\n",
    "print(\"\\n#-----------------------------------------------------\")\n",
    "print(f\"# Denormalized Model Accuracy: {accuracy_percentage:.2f}%\")\n",
    "print(\"#-----------------------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Zw_4uhM2LD90"
   },
   "source": [
    "# Generate aTensorflow Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LrW70R5kKTU",
    "outputId": "6481d3bd-2407-4416-dc94-e303f16348b4"
   },
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    "  for _ in range(500):\n",
    "    yield([feature_train.astype(np.float32)])\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(MODEL_NO_QUANT_TFLITE)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Define your input here. I am using random for the simplicity\n",
    "input_data = feature_test.to_numpy().astype(np.float32)\n",
    "\n",
    "print(input_data)\n",
    "print(input_data.shape[0])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert DataFrame to numpy array for correct indexing\n",
    "\n",
    "# Assuming `feature_test_np` is a 2D numpy array with shape (808, 8)\n",
    "for i in range(input_data.shape[0]):\n",
    "    single_instance = np.expand_dims(input_data[i], axis=0)  # Reshape from (8,) to (1, 8)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], single_instance)\n",
    "    interpreter.invoke()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Time taken\n",
    "print(f\"Time taken for non-quantized prediction: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(MODEL_TFLITE)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Define your input here. I am using random for the simplicity\n",
    "# Assuming `input_data_normalized` is your normalized test data\n",
    "input_data_quantized = (feature_test * 127).astype(np.int8)\n",
    "input_data_quantized_np = input_data_quantized.to_numpy()\n",
    "print(input_data_quantized)\n",
    "print(input_data_quantized_np.shape[0])\n",
    "\n",
    "start_time = time.time()\n",
    "# Assuming `input_data_quantized_np` is a 2D numpy array with shape (808, 8)\n",
    "for i in range(input_data_quantized_np.shape[0]):\n",
    "    single_instance = np.expand_dims(input_data_quantized_np[i], axis=0)  # Reshape from (8,) to (1, 8)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], single_instance)\n",
    "    interpreter.invoke()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Time taken\n",
    "print(f\"Time taken for quantized prediction: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "m6EhtS39EDEv",
    "outputId": "1e7824d9-0762-49d1-80ad-79338fdd8cd8"
   },
   "outputs": [],
   "source": [
    "size_tf_small = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
    "pd.DataFrame.from_records([[\"Tensorflow\", f\"{size_tf_small} bytes\",\"\"]], columns = [\"Model\", \"Size\", \"\"], index=\"Model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FD9GFALcf-OO"
   },
   "source": [
    "### Compare Quantized and Non Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awHQYoCq_rf5"
   },
   "outputs": [],
   "source": [
    "# Calculate size\n",
    "size_tf = os.path.getsize(MODEL_TF)\n",
    "size_no_quant_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
    "size_tflite = os.path.getsize(MODEL_TFLITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "kZMPchUZ_xkL",
    "outputId": "ab2a2380-70c5-4526-8e6e-5727b7a07d57"
   },
   "outputs": [],
   "source": [
    "# Compare sizes\n",
    "pd.DataFrame.from_records(\n",
    "    [\n",
    "     [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \"],\n",
    "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\"]],\n",
    "     columns = [\"Model\", \"Size\"], index=\"Model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PBNVtMwdALzB"
   },
   "source": [
    "### Generate TF Lite for Microcontroller Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJ2-NomQ_zoK",
    "outputId": "c6e476d5-964a-4b4f-8f35-65e8b0a259ff"
   },
   "outputs": [],
   "source": [
    "# Install xxd if it is not available\n",
    "!apt-get update && apt-get -qq install xxd\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/position_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mD6qtAejAID7",
    "outputId": "e2b00c29-d143-45aa-c43b-3a10f65cebfc"
   },
   "outputs": [],
   "source": [
    "# Print the C source file\n",
    "!cat {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxTCnzcuCpNp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ACELS.V10_xyz.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
